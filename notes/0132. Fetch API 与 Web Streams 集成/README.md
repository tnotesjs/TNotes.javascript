# [0132. Fetch API ä¸ Web Streams é›†æˆ](https://github.com/tnotesjs/TNotes.javascript/tree/main/notes/0132.%20Fetch%20API%20%E4%B8%8E%20Web%20Streams%20%E9%9B%86%E6%88%90)

<!-- region:toc -->

- [1. ğŸ¯ æœ¬èŠ‚å†…å®¹](#1--æœ¬èŠ‚å†…å®¹)
- [2. ğŸ«§ è¯„ä»·](#2--è¯„ä»·)
- [3. ğŸ¤” å¦‚ä½•ä½¿ç”¨æµå¼å¤„ç†æ¥æ˜¾ç¤ºä¸‹è½½è¿›åº¦ ï¼Ÿ](#3--å¦‚ä½•ä½¿ç”¨æµå¼å¤„ç†æ¥æ˜¾ç¤ºä¸‹è½½è¿›åº¦-)
  - [3.1. åŸºæœ¬å®ç°](#31-åŸºæœ¬å®ç°)
  - [3.2. ä½¿ç”¨ TransformStream å®ç°](#32-ä½¿ç”¨-transformstream-å®ç°)
  - [3.3. å¸¦é€Ÿåº¦è®¡ç®—çš„è¿›åº¦](#33-å¸¦é€Ÿåº¦è®¡ç®—çš„è¿›åº¦)
  - [3.4. å®æˆ˜ï¼šå›¾ç‰‡ä¸‹è½½å¹¶é¢„è§ˆ](#34-å®æˆ˜å›¾ç‰‡ä¸‹è½½å¹¶é¢„è§ˆ)
- [4. ğŸ¤” ä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥å°† Response.body ç”¨äºå¤šä¸ªè¯»å–å™¨ ï¼Ÿ](#4--ä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥å°†-responsebody-ç”¨äºå¤šä¸ªè¯»å–å™¨-)
  - [4.1. é”å®šæœºåˆ¶æ¼”ç¤º](#41-é”å®šæœºåˆ¶æ¼”ç¤º)
  - [4.2. ä½¿ç”¨ tee() å®ç°å¤šæ¬¡è¯»å–](#42-ä½¿ç”¨-tee-å®ç°å¤šæ¬¡è¯»å–)
  - [4.3. å®æˆ˜ï¼šåŒæ—¶ç¼“å­˜å’Œå¤„ç†å“åº”](#43-å®æˆ˜åŒæ—¶ç¼“å­˜å’Œå¤„ç†å“åº”)
  - [4.4. å¤šä¸ªæ¶ˆè´¹è€…çš„åœºæ™¯](#44-å¤šä¸ªæ¶ˆè´¹è€…çš„åœºæ™¯)
  - [4.5. é”å®šçš„æ›¿ä»£æ–¹æ¡ˆï¼šå…ˆè¯»å–å…¨éƒ¨æ•°æ®](#45-é”å®šçš„æ›¿ä»£æ–¹æ¡ˆå…ˆè¯»å–å…¨éƒ¨æ•°æ®)
  - [4.6. å¯¹æ¯”è¡¨æ ¼](#46-å¯¹æ¯”è¡¨æ ¼)
- [5. ğŸ¤” å¦‚ä½•å®ç°å¤§æ–‡ä»¶çš„åˆ†å—ä¸Šä¼  ï¼Ÿ](#5--å¦‚ä½•å®ç°å¤§æ–‡ä»¶çš„åˆ†å—ä¸Šä¼ -)
  - [5.1. åŸºç¡€åˆ†å—ä¸Šä¼ ](#51-åŸºç¡€åˆ†å—ä¸Šä¼ )
  - [5.2. ä½¿ç”¨ ReadableStream æµå¼ä¸Šä¼ ](#52-ä½¿ç”¨-readablestream-æµå¼ä¸Šä¼ )
  - [5.3. å¸¦è¿›åº¦ç›‘æ§çš„æµå¼ä¸Šä¼ ](#53-å¸¦è¿›åº¦ç›‘æ§çš„æµå¼ä¸Šä¼ )
  - [5.4. æ–­ç‚¹ç»­ä¼ å®ç°](#54-æ–­ç‚¹ç»­ä¼ å®ç°)
  - [5.5. å¹¶å‘åˆ†å—ä¸Šä¼ ](#55-å¹¶å‘åˆ†å—ä¸Šä¼ )
- [6. ğŸ¤” å¦‚ä½•å¤„ç†æµå¼ JSON æ•°æ® ï¼Ÿ](#6--å¦‚ä½•å¤„ç†æµå¼-json-æ•°æ®-)
  - [6.1. è§£æ NDJSONï¼ˆæ¢è¡Œåˆ†éš” JSONï¼‰](#61-è§£æ-ndjsonæ¢è¡Œåˆ†éš”-json)
  - [6.2. è§£ææµå¼ JSON æ•°ç»„](#62-è§£ææµå¼-json-æ•°ç»„)
  - [6.3. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ](#63-ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ)
  - [6.4. å®æˆ˜ï¼šå¤„ç†å¤§å‹ API å“åº”](#64-å®æˆ˜å¤„ç†å¤§å‹-api-å“åº”)
  - [6.5. å¤„ç†æœåŠ¡å™¨å‘é€äº‹ä»¶ï¼ˆSSEï¼‰](#65-å¤„ç†æœåŠ¡å™¨å‘é€äº‹ä»¶sse)
- [7. ğŸ’» demos.1 - å®ç°å¸¦è¿›åº¦æ¡çš„æ–‡ä»¶ä¸‹è½½](#7--demos1---å®ç°å¸¦è¿›åº¦æ¡çš„æ–‡ä»¶ä¸‹è½½)
- [8. ğŸ’» demos.2 - æµå¼å¤„ç†æœåŠ¡å™¨å‘é€äº‹ä»¶ SSE](#8--demos2---æµå¼å¤„ç†æœåŠ¡å™¨å‘é€äº‹ä»¶-sse)
- [9. ğŸ”— å¼•ç”¨](#9--å¼•ç”¨)

<!-- endregion:toc -->

## 1. ğŸ¯ æœ¬èŠ‚å†…å®¹

- Response.body çš„ ReadableStream ç±»å‹
- Request.body çš„æ„é€ ä¸ä½¿ç”¨
- ä¸‹è½½è¿›åº¦ç›‘æ§çš„å®ç°æ–¹å¼
- åˆ†å—ä¸Šä¼ çš„æµå¼å¤„ç†
- æµå¼ JSON è§£æçš„åŸºç¡€åœºæ™¯
- SSEï¼ˆServer-Sent Eventsï¼‰çš„æµå¼å¤„ç†

## 2. ğŸ«§ è¯„ä»·

Fetch API ä¸ Web Streams çš„é›†æˆæ˜¯ç°ä»£ç½‘ç»œåº”ç”¨çš„æ ¸å¿ƒèƒ½åŠ›ã€‚Response.body å’Œ Request.body éƒ½æ˜¯ ReadableStreamï¼Œæ”¯æŒæµå¼è¯»å–å’Œå†™å…¥ã€‚ä¸‹è½½è¿›åº¦é€šè¿‡è¯»å–å™¨é€å—ç»Ÿè®¡å®ç°ï¼Œä¸Šä¼ è¿›åº¦éœ€é…åˆæœåŠ¡å™¨æ”¯æŒã€‚æµå¼ JSON è§£æé€‚åˆå¤„ç†å¤§å‹æ•°ç»„æˆ– NDJSON æ ¼å¼ã€‚ç†è§£æµé”å®šæœºåˆ¶å¾ˆé‡è¦ï¼ŒResponse.body ä¸€æ—¦è¢«è¯»å–å°±ä¼šé”å®šï¼Œéœ€ç”¨ tee() å®ç°å¤šæ¬¡æ¶ˆè´¹ã€‚

## 3. ğŸ¤” å¦‚ä½•ä½¿ç”¨æµå¼å¤„ç†æ¥æ˜¾ç¤ºä¸‹è½½è¿›åº¦ ï¼Ÿ

é€šè¿‡ Response.body çš„ ReadableStream é€å—è¯»å–ï¼Œç´¯è®¡å·²æ¥æ”¶å­—èŠ‚æ•°ï¼Œç»“åˆ Content-Length è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”ã€‚

### 3.1. åŸºæœ¬å®ç°

```js
async function downloadWithProgress(url, onProgress) {
  const response = await fetch(url)

  // è·å–æ€»å¤§å°
  const contentLength = response.headers.get('Content-Length')
  const total = parseInt(contentLength, 10)

  if (!total) {
    console.warn('æœåŠ¡å™¨æœªæä¾› Content-Length')
  }

  const reader = response.body.getReader()
  let receivedLength = 0
  const chunks = []

  while (true) {
    const { done, value } = await reader.read()

    if (done) break

    chunks.push(value)
    receivedLength += value.length

    // è§¦å‘è¿›åº¦å›è°ƒ
    const progress = total ? (receivedLength / total) * 100 : 0
    onProgress({ receivedLength, total, progress })
  }

  // åˆå¹¶æ‰€æœ‰å—
  const allChunks = new Uint8Array(receivedLength)
  let position = 0
  for (const chunk of chunks) {
    allChunks.set(chunk, position)
    position += chunk.length
  }

  return allChunks
}

// ä½¿ç”¨
const data = await downloadWithProgress('/api/large-file', (progress) => {
  console.log(`å·²ä¸‹è½½: ${progress.progress.toFixed(2)}%`)
  console.log(`${progress.receivedLength} / ${progress.total} å­—èŠ‚`)
})
```

### 3.2. ä½¿ç”¨ TransformStream å®ç°

```js
function createProgressStream(total, onProgress) {
  let loaded = 0

  return new TransformStream({
    transform(chunk, controller) {
      loaded += chunk.byteLength
      const progress = total ? (loaded / total) * 100 : 0

      onProgress({ loaded, total, progress })
      controller.enqueue(chunk)
    },
  })
}

async function downloadWithProgressStream(url) {
  const response = await fetch(url)
  const total = parseInt(response.headers.get('Content-Length'), 10)

  const progressStream = createProgressStream(total, (progress) => {
    updateProgressBar(progress.progress)
  })

  // ç®¡é“å¤„ç†
  const processedStream = response.body.pipeThrough(progressStream)

  // ç»§ç»­å¤„ç†æ•°æ®
  await processedStream.pipeTo(
    new WritableStream({
      write(chunk) {
        saveChunk(chunk)
      },
    })
  )
}
```

### 3.3. å¸¦é€Ÿåº¦è®¡ç®—çš„è¿›åº¦

```js
class DownloadMonitor {
  constructor(total) {
    this.total = total
    this.loaded = 0
    this.startTime = Date.now()
    this.lastTime = this.startTime
    this.lastLoaded = 0
  }

  update(chunkSize) {
    this.loaded += chunkSize
    const now = Date.now()
    const timeDiff = (now - this.lastTime) / 1000
    const loadedDiff = this.loaded - this.lastLoaded

    // è®¡ç®—å³æ—¶é€Ÿåº¦
    const speed = timeDiff > 0 ? loadedDiff / timeDiff : 0

    // è®¡ç®—å‰©ä½™æ—¶é—´
    const remaining = this.total - this.loaded
    const eta = speed > 0 ? remaining / speed : 0

    this.lastTime = now
    this.lastLoaded = this.loaded

    return {
      progress: this.total ? (this.loaded / this.total) * 100 : 0,
      loaded: this.loaded,
      total: this.total,
      speed,
      eta,
    }
  }
}

async function downloadWithStats(url) {
  const response = await fetch(url)
  const total = parseInt(response.headers.get('Content-Length'), 10)
  const monitor = new DownloadMonitor(total)

  const reader = response.body.getReader()
  const chunks = []

  while (true) {
    const { done, value } = await reader.read()
    if (done) break

    chunks.push(value)
    const stats = monitor.update(value.length)

    console.log(`è¿›åº¦: ${stats.progress.toFixed(1)}%`)
    console.log(`é€Ÿåº¦: ${(stats.speed / 1024).toFixed(2)} KB/s`)
    console.log(`å‰©ä½™æ—¶é—´: ${stats.eta.toFixed(0)} ç§’`)
  }

  return new Blob(chunks)
}
```

### 3.4. å®æˆ˜ï¼šå›¾ç‰‡ä¸‹è½½å¹¶é¢„è§ˆ

```js
async function downloadImageWithProgress(url, imgElement, progressCallback) {
  const response = await fetch(url)
  const total = parseInt(response.headers.get('Content-Length'), 10)

  const stream = response.body.pipeThrough(
    new TransformStream({
      transform(chunk, controller) {
        progressCallback({
          loaded: (controller.loaded =
            (controller.loaded || 0) + chunk.byteLength),
          total,
        })
        controller.enqueue(chunk)
      },
    })
  )

  // è½¬æ¢ä¸º Blob
  const blob = await new Response(stream).blob()

  // æ˜¾ç¤ºå›¾ç‰‡
  imgElement.src = URL.createObjectURL(blob)
}

// ä½¿ç”¨
downloadImageWithProgress(
  '/images/large.jpg',
  document.getElementById('preview'),
  ({ loaded, total }) => {
    const percent = ((loaded / total) * 100).toFixed(1)
    document.getElementById('progress').textContent = `${percent}%`
  }
)
```

æµå¼è¿›åº¦çš„å…³é”®æ˜¯é€å—ç´¯åŠ ï¼Œç»“åˆ Content-Length è®¡ç®—ç™¾åˆ†æ¯”ã€‚

## 4. ğŸ¤” ä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥å°† Response.body ç”¨äºå¤šä¸ªè¯»å–å™¨ ï¼Ÿ

å› ä¸º ReadableStream ä¸€æ—¦è¢«è¯»å–å°±ä¼šé”å®šï¼Œåªèƒ½æœ‰ä¸€ä¸ªæ´»åŠ¨è¯»å–å™¨ï¼Œéœ€ä½¿ç”¨ tee() æ–¹æ³•åˆ›å»ºåˆ†æ”¯ã€‚

### 4.1. é”å®šæœºåˆ¶æ¼”ç¤º

```js
const response = await fetch('/api/data')

// ç¬¬ä¸€æ¬¡è·å–è¯»å–å™¨æˆåŠŸ
const reader1 = response.body.getReader()

// âŒ ç¬¬äºŒæ¬¡è·å–è¯»å–å™¨å¤±è´¥
try {
  const reader2 = response.body.getReader()
} catch (error) {
  console.error(error.message) // ReadableStream is locked
}

// æ£€æŸ¥é”å®šçŠ¶æ€
console.log(response.body.locked) // true

// é‡Šæ”¾é”
reader1.releaseLock()
console.log(response.body.locked) // false
```

### 4.2. ä½¿ç”¨ tee() å®ç°å¤šæ¬¡è¯»å–

```js
const response = await fetch('/api/data')

// åˆ›å»ºä¸¤ä¸ªç‹¬ç«‹åˆ†æ”¯
const [stream1, stream2] = response.body.tee()

// âš ï¸ åŸå§‹æµå·²é”å®š
console.log(response.body.locked) // true

// âœ… ä¸¤ä¸ªåˆ†æ”¯å¯ç‹¬ç«‹è¯»å–
const reader1 = stream1.getReader()
const reader2 = stream2.getReader()

// åˆ†æ”¯ 1ï¼šä¿å­˜åˆ°ç¼“å­˜
const cache = []
while (true) {
  const { done, value } = await reader1.read()
  if (done) break
  cache.push(value)
}

// åˆ†æ”¯ 2ï¼šæ˜¾ç¤ºå†…å®¹
while (true) {
  const { done, value } = await reader2.read()
  if (done) break
  displayData(value)
}
```

### 4.3. å®æˆ˜ï¼šåŒæ—¶ç¼“å­˜å’Œå¤„ç†å“åº”

```js
async function fetchAndCache(url) {
  const response = await fetch(url)
  const [cacheStream, processStream] = response.body.tee()

  // åˆ†æ”¯ 1ï¼šç¼“å­˜åˆ° Cache API
  const cachePromise = caches.open('api-cache').then(async (cache) => {
    await cache.put(
      url,
      new Response(cacheStream, {
        headers: response.headers,
      })
    )
    console.log('âœ… ç¼“å­˜å®Œæˆ')
  })

  // åˆ†æ”¯ 2ï¼šè§£æ JSON
  const dataPromise = new Response(processStream).json()

  // ç­‰å¾…ä¸¤ä¸ªæ“ä½œå®Œæˆ
  const [_, data] = await Promise.all([cachePromise, dataPromise])
  return data
}
```

### 4.4. å¤šä¸ªæ¶ˆè´¹è€…çš„åœºæ™¯

```js
async function multipleConsumers(url) {
  const response = await fetch(url)

  // åˆ›å»ºä¸‰ä¸ªåˆ†æ”¯
  const [stream1, temp] = response.body.tee()
  const [stream2, stream3] = temp.tee()

  // æ¶ˆè´¹è€… 1ï¼šè®¡ç®—å“ˆå¸Œ
  const hashPromise = stream1.pipeThrough(new TextDecoderStream()).pipeTo(
    new WritableStream({
      write(chunk) {
        updateHash(chunk)
      },
    })
  )

  // æ¶ˆè´¹è€… 2ï¼šä¿å­˜åˆ°æ–‡ä»¶
  const savePromise = stream2.pipeTo(createFileWriteStream('output.txt'))

  // æ¶ˆè´¹è€… 3ï¼šå®æ—¶æ˜¾ç¤º
  const displayPromise = stream3.pipeThrough(new TextDecoderStream()).pipeTo(
    new WritableStream({
      write(chunk) {
        console.log(chunk)
      },
    })
  )

  await Promise.all([hashPromise, savePromise, displayPromise])
}
```

### 4.5. é”å®šçš„æ›¿ä»£æ–¹æ¡ˆï¼šå…ˆè¯»å–å…¨éƒ¨æ•°æ®

```js
// æ–¹æ¡ˆ 1ï¼šè½¬æ¢ä¸º ArrayBuffer
const response = await fetch('/api/data')
const buffer = await response.arrayBuffer()

// å¯ä»¥å¤šæ¬¡ä½¿ç”¨
const blob1 = new Blob([buffer])
const blob2 = new Blob([buffer])
const text = new TextDecoder().decode(buffer)

// æ–¹æ¡ˆ 2ï¼šè½¬æ¢ä¸º Blob
const blob = await response.blob()
const stream1 = blob.stream()
const stream2 = blob.stream()
```

### 4.6. å¯¹æ¯”è¡¨æ ¼

| ç‰¹æ€§ | ç›´æ¥è¯»å– Response.body | ä½¿ç”¨ tee() | å…ˆè½¬æ¢ä¸º Blob/ArrayBuffer |
| --- | --- | --- | --- |
| å†…å­˜å ç”¨ | æœ€ä½ï¼ˆé€å—å¤„ç†ï¼‰ | ä¸­ç­‰ï¼ˆéœ€ç¼“å†²ï¼‰ | æœ€é«˜ï¼ˆå…¨éƒ¨åŠ è½½ï¼‰ |
| å¤šæ¬¡è¯»å– | âŒ ä¸æ”¯æŒ | âœ… æ”¯æŒï¼ˆåˆ›å»ºåˆ†æ”¯ï¼‰ | âœ… æ”¯æŒï¼ˆæ— é™æ¬¡ï¼‰ |
| æµå¼å¤„ç† | âœ… æ”¯æŒ | âœ… æ”¯æŒ | âŒ ä¸æ”¯æŒ |
| é€‚ç”¨åœºæ™¯ | å•æ¬¡å¤„ç†å¤§æ–‡ä»¶ | åŒæ—¶ä¿å­˜å’Œæ˜¾ç¤º | å°æ–‡ä»¶å¤šæ¬¡ä½¿ç”¨ |

æµé”å®šæ˜¯è®¾è®¡ç‰¹æ€§ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼Œä½¿ç”¨ tee() æˆ–å®Œæ•´è¯»å–å¯ç»•è¿‡é™åˆ¶ã€‚

## 5. ğŸ¤” å¦‚ä½•å®ç°å¤§æ–‡ä»¶çš„åˆ†å—ä¸Šä¼  ï¼Ÿ

å°†æ–‡ä»¶åˆ†å‰²æˆå¤šä¸ªå—ï¼Œé€ä¸ªä¸Šä¼ ï¼Œæ¯å—åˆ›å»ºç‹¬ç«‹çš„ fetch è¯·æ±‚ï¼Œæˆ–ä½¿ç”¨ ReadableStream ä½œä¸º Request.bodyã€‚

### 5.1. åŸºç¡€åˆ†å—ä¸Šä¼ 

```js
async function uploadFileInChunks(file, url, chunkSize = 1024 * 1024) {
  const totalChunks = Math.ceil(file.size / chunkSize)

  for (let i = 0; i < totalChunks; i++) {
    const start = i * chunkSize
    const end = Math.min(start + chunkSize, file.size)
    const chunk = file.slice(start, end)

    await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/octet-stream',
        'X-Chunk-Index': i,
        'X-Total-Chunks': totalChunks,
        'X-File-Name': file.name,
      },
      body: chunk,
    })

    const progress = ((i + 1) / totalChunks) * 100
    console.log(`ä¸Šä¼ è¿›åº¦: ${progress.toFixed(1)}%`)
  }

  console.log('âœ… ä¸Šä¼ å®Œæˆ')
}

// ä½¿ç”¨
const fileInput = document.getElementById('file')
uploadFileInChunks(fileInput.files[0], '/api/upload')
```

### 5.2. ä½¿ç”¨ ReadableStream æµå¼ä¸Šä¼ 

```js
function createFileStream(file, chunkSize = 64 * 1024) {
  let offset = 0

  return new ReadableStream({
    async pull(controller) {
      if (offset >= file.size) {
        controller.close()
        return
      }

      const chunk = file.slice(offset, offset + chunkSize)
      const buffer = await chunk.arrayBuffer()

      controller.enqueue(new Uint8Array(buffer))
      offset += chunkSize
    },
  })
}

async function uploadFileStream(file, url) {
  const stream = createFileStream(file)

  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/octet-stream',
      'X-File-Name': file.name,
      'X-File-Size': file.size,
    },
    body: stream,
    duplex: 'half', // å…è®¸è¯·æ±‚ä½“ä¸ºæµ
  })

  return response.json()
}
```

### 5.3. å¸¦è¿›åº¦ç›‘æ§çš„æµå¼ä¸Šä¼ 

```js
function createUploadStream(file, onProgress) {
  let uploaded = 0
  const total = file.size

  return new ReadableStream({
    async pull(controller) {
      const chunkSize = 64 * 1024
      if (uploaded >= total) {
        controller.close()
        return
      }

      const chunk = file.slice(uploaded, uploaded + chunkSize)
      const buffer = await chunk.arrayBuffer()

      controller.enqueue(new Uint8Array(buffer))
      uploaded += buffer.byteLength

      onProgress({
        uploaded,
        total,
        progress: (uploaded / total) * 100,
      })
    },
  })
}

async function uploadWithProgress(file, url) {
  const stream = createUploadStream(file, (progress) => {
    console.log(`ä¸Šä¼ è¿›åº¦: ${progress.progress.toFixed(1)}%`)
    updateProgressBar(progress.progress)
  })

  await fetch(url, {
    method: 'POST',
    body: stream,
    duplex: 'half',
  })
}
```

### 5.4. æ–­ç‚¹ç»­ä¼ å®ç°

```js
async function resumableUpload(file, url) {
  // æŸ¥è¯¢å·²ä¸Šä¼ çš„å­—èŠ‚æ•°
  const statusResponse = await fetch(`${url}/status`, {
    method: 'GET',
    headers: { 'X-File-ID': file.name },
  })

  const { uploadedBytes } = await statusResponse.json()
  console.log(`å·²ä¸Šä¼ : ${uploadedBytes} å­—èŠ‚ï¼Œç»§ç»­ä¸Šä¼ ...`)

  // ä»æ–­ç‚¹å¤„ç»§ç»­
  const remainingData = file.slice(uploadedBytes)

  const stream = new ReadableStream({
    async start(controller) {
      const chunkSize = 1024 * 1024
      let offset = 0

      while (offset < remainingData.size) {
        const chunk = remainingData.slice(offset, offset + chunkSize)
        const buffer = await chunk.arrayBuffer()
        controller.enqueue(new Uint8Array(buffer))
        offset += chunkSize
      }

      controller.close()
    },
  })

  await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/octet-stream',
      'X-File-ID': file.name,
      'X-Upload-Offset': uploadedBytes,
    },
    body: stream,
    duplex: 'half',
  })
}
```

### 5.5. å¹¶å‘åˆ†å—ä¸Šä¼ 

```js
async function parallelChunkUpload(file, url, concurrency = 3) {
  const chunkSize = 1024 * 1024
  const totalChunks = Math.ceil(file.size / chunkSize)

  // åˆ›å»ºä¸Šä¼ ä»»åŠ¡é˜Ÿåˆ—
  const uploadChunk = async (index) => {
    const start = index * chunkSize
    const end = Math.min(start + chunkSize, file.size)
    const chunk = file.slice(start, end)

    await fetch(url, {
      method: 'POST',
      headers: {
        'X-Chunk-Index': index,
        'X-Total-Chunks': totalChunks,
      },
      body: chunk,
    })

    return index
  }

  // å¹¶å‘æ§åˆ¶
  const results = []
  for (let i = 0; i < totalChunks; i += concurrency) {
    const batch = []
    for (let j = 0; j < concurrency && i + j < totalChunks; j++) {
      batch.push(uploadChunk(i + j))
    }
    const batchResults = await Promise.all(batch)
    results.push(...batchResults)

    console.log(`å·²å®Œæˆ: ${results.length}/${totalChunks} å—`)
  }

  // é€šçŸ¥æœåŠ¡å™¨åˆå¹¶
  await fetch(`${url}/merge`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ totalChunks, fileName: file.name }),
  })
}
```

æµå¼ä¸Šä¼ çš„å…³é”®æ˜¯å°† ReadableStream ä½œä¸º Request.bodyï¼Œé…åˆ duplex: 'half' é€‰é¡¹ã€‚

## 6. ğŸ¤” å¦‚ä½•å¤„ç†æµå¼ JSON æ•°æ® ï¼Ÿ

å¯¹äº JSON æ•°ç»„æˆ– NDJSON æ ¼å¼ï¼Œä½¿ç”¨ TransformStream é€è¡Œè§£æï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½å¤§å‹ JSONã€‚

### 6.1. è§£æ NDJSONï¼ˆæ¢è¡Œåˆ†éš” JSONï¼‰

```js
function createNDJSONParser() {
  let buffer = ''

  return new TransformStream({
    transform(chunk, controller) {
      buffer += chunk

      const lines = buffer.split('\n')
      buffer = lines.pop() // ä¿ç•™ä¸å®Œæ•´çš„è¡Œ

      for (const line of lines) {
        if (line.trim()) {
          try {
            const obj = JSON.parse(line)
            controller.enqueue(obj)
          } catch (error) {
            console.error('JSON è§£æé”™è¯¯:', line)
          }
        }
      }
    },
    flush(controller) {
      // å¤„ç†æœ€åä¸€è¡Œ
      if (buffer.trim()) {
        try {
          controller.enqueue(JSON.parse(buffer))
        } catch (error) {
          console.error('æœ€åä¸€è¡Œè§£æé”™è¯¯:', buffer)
        }
      }
    },
  })
}

async function processNDJSON(url) {
  const response = await fetch(url)

  await response.body
    .pipeThrough(new TextDecoderStream())
    .pipeThrough(createNDJSONParser())
    .pipeTo(
      new WritableStream({
        write(obj) {
          console.log('è§£æå¯¹è±¡:', obj)
          processObject(obj)
        },
      })
    )
}
```

### 6.2. è§£ææµå¼ JSON æ•°ç»„

```js
function createJSONArrayParser() {
  let buffer = ''
  let depth = 0
  let inArray = false

  return new TransformStream({
    transform(chunk, controller) {
      buffer += chunk

      let objStart = -1

      for (let i = 0; i < buffer.length; i++) {
        const char = buffer[i]

        if (char === '[' && depth === 0) {
          inArray = true
          depth++
          continue
        }

        if (!inArray) continue

        if (char === '{' && depth === 1) {
          objStart = i
        }

        if (char === '{') depth++
        if (char === '}') depth--

        // æ‰¾åˆ°å®Œæ•´å¯¹è±¡
        if (depth === 1 && objStart !== -1 && char === '}') {
          const objStr = buffer.substring(objStart, i + 1)
          try {
            const obj = JSON.parse(objStr)
            controller.enqueue(obj)
          } catch (error) {
            console.error('è§£æé”™è¯¯:', objStr)
          }

          buffer = buffer.substring(i + 1)
          i = 0
          objStart = -1
        }
      }
    },
  })
}

async function processJSONArray(url) {
  const response = await fetch(url)

  await response.body
    .pipeThrough(new TextDecoderStream())
    .pipeThrough(createJSONArrayParser())
    .pipeTo(
      new WritableStream({
        write(item) {
          console.log('æ•°ç»„é¡¹:', item)
        },
      })
    )
}
```

### 6.3. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ

```js
function createSimpleJSONStreamParser() {
  let buffer = ''

  return new TransformStream({
    transform(chunk, controller) {
      buffer += chunk

      // åŒ¹é… JSON å¯¹è±¡ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰
      const regex = /\{[^{}]*\}/g
      let match

      while ((match = regex.exec(buffer)) !== null) {
        try {
          const obj = JSON.parse(match[0])
          controller.enqueue(obj)
        } catch (error) {
          // ä¸å®Œæ•´çš„å¯¹è±¡ï¼Œç»§ç»­ç¼“å†²
        }
      }

      // ä¿ç•™æœªåŒ¹é…çš„éƒ¨åˆ†
      const lastMatch = buffer.lastIndexOf('}')
      if (lastMatch !== -1) {
        buffer = buffer.substring(lastMatch + 1)
      }
    },
  })
}
```

### 6.4. å®æˆ˜ï¼šå¤„ç†å¤§å‹ API å“åº”

```js
async function fetchLargeDataset(url) {
  const response = await fetch(url)

  const stats = { count: 0, totalSize: 0 }
  const results = []

  await response.body
    .pipeThrough(new TextDecoderStream())
    .pipeThrough(createNDJSONParser())
    .pipeThrough(
      new TransformStream({
        transform(obj, controller) {
          // æ•°æ®è¿‡æ»¤
          if (obj.status === 'active') {
            controller.enqueue(obj)
          }
        },
      })
    )
    .pipeTo(
      new WritableStream({
        write(obj) {
          results.push(obj)
          stats.count++
          stats.totalSize += JSON.stringify(obj).length

          // æ¯ 100 æ¡æ‰¹é‡å¤„ç†
          if (results.length >= 100) {
            processBatch(results.splice(0, 100))
          }
        },
        close() {
          // å¤„ç†å‰©ä½™æ•°æ®
          if (results.length > 0) {
            processBatch(results)
          }
          console.log(`å¤„ç†å®Œæˆ: ${stats.count} æ¡è®°å½•`)
        },
      })
    )
}
```

### 6.5. å¤„ç†æœåŠ¡å™¨å‘é€äº‹ä»¶ï¼ˆSSEï¼‰

```js
function createSSEParser() {
  let buffer = ''

  return new TransformStream({
    transform(chunk, controller) {
      buffer += chunk

      const lines = buffer.split('\n\n')
      buffer = lines.pop()

      for (const line of lines) {
        if (line.startsWith('data:')) {
          const data = line.substring(5).trim()
          try {
            const obj = JSON.parse(data)
            controller.enqueue(obj)
          } catch {
            controller.enqueue({ raw: data })
          }
        }
      }
    },
  })
}

async function listenToSSE(url) {
  const response = await fetch(url)

  await response.body
    .pipeThrough(new TextDecoderStream())
    .pipeThrough(createSSEParser())
    .pipeTo(
      new WritableStream({
        write(event) {
          console.log('SSE äº‹ä»¶:', event)
          handleEvent(event)
        },
      })
    )
}
```

æµå¼ JSON è§£æé€‚åˆå¤„ç†å¤§æ•°æ®é›†ï¼Œå…³é”®æ˜¯é€è¡Œæˆ–é€å¯¹è±¡è§£æï¼Œé¿å…å†…å­˜æº¢å‡ºã€‚

## 7. ğŸ’» demos.1 - å®ç°å¸¦è¿›åº¦æ¡çš„æ–‡ä»¶ä¸‹è½½

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ ReadableStream å®ç°æ–‡ä»¶ä¸‹è½½è¿›åº¦ç›‘æ§ï¼ŒåŒ…æ‹¬ä¸‹è½½é€Ÿåº¦ã€å‰©ä½™æ—¶é—´ç­‰ç»Ÿè®¡ä¿¡æ¯ã€‚

**è¿è¡Œæ–¹å¼**ï¼šåœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ [demos/1/1.html](demos/1/1.html)

**æ ¸å¿ƒåŠŸèƒ½**ï¼š

- æ¨¡æ‹Ÿä¸åŒå¤§å°æ–‡ä»¶çš„ä¸‹è½½
- å®æ—¶æ˜¾ç¤ºä¸‹è½½è¿›åº¦ç™¾åˆ†æ¯”
- è®¡ç®—ä¸‹è½½é€Ÿåº¦å’Œå‰©ä½™æ—¶é—´
- é€å—ç´¯åŠ æ•°æ®å¹¶æœ€ç»ˆåˆå¹¶

**å…³é”®ä»£ç **ï¼š

```js
class DownloadMonitor {
  constructor(total) {
    this.total = total
    this.loaded = 0
    this.startTime = Date.now()
  }

  update(chunkSize) {
    this.loaded += chunkSize
    const elapsed = (Date.now() - this.startTime) / 1000
    const speed = this.loaded / elapsed
    const eta = (this.total - this.loaded) / speed

    return {
      progress: (this.loaded / this.total) * 100,
      speed,
      eta,
    }
  }
}

const reader = stream.getReader()
while (true) {
  const { done, value } = await reader.read()
  if (done) break

  const stats = monitor.update(value.length)
  updateUI(stats)
}
```

## 8. ğŸ’» demos.2 - æµå¼å¤„ç†æœåŠ¡å™¨å‘é€äº‹ä»¶ SSE

æ¼”ç¤ºå¦‚ä½•è§£æ SSEï¼ˆServer-Sent Eventsï¼‰å’Œ NDJSON æ ¼å¼çš„æµå¼æ•°æ®ï¼Œå®æ—¶æ˜¾ç¤ºäº‹ä»¶å’Œç»Ÿè®¡ä¿¡æ¯ã€‚

**è¿è¡Œæ–¹å¼**ï¼šåœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ [demos/2/2.html](demos/2/2.html)

**æ ¸å¿ƒåŠŸèƒ½**ï¼š

- SSE äº‹ä»¶æµçš„è§£æ
- NDJSON æ ¼å¼çš„é€è¡Œè§£æ
- å®æ—¶ç»Ÿè®¡äº‹ä»¶æ•°é‡å’Œæ•°æ®é‡
- æ”¯æŒå¯åŠ¨ã€åœæ­¢è¿æ¥

**å…³é”®ä»£ç **ï¼š

```js
function createSSEParser() {
  let buffer = ''

  return new TransformStream({
    transform(chunk, controller) {
      buffer += chunk

      const events = buffer.split('\n\n')
      buffer = events.pop()

      for (const event of events) {
        const parsed = {}
        for (const line of event.split('\n')) {
          if (line.startsWith('data:')) {
            parsed.data = line.substring(5).trim()
          }
        }
        if (parsed.data) controller.enqueue(parsed)
      }
    },
  })
}

await stream
  .pipeThrough(new TextDecoderStream())
  .pipeThrough(createSSEParser())
  .pipeTo(new WritableStream({ write: handleEvent }))
```

## 9. ğŸ”— å¼•ç”¨

- [Fetch Standard - Request Body][1]
- [Fetch Standard - Response Body][2]
- [MDN - Using Fetch][3]
- [MDN - ReadableStream][4]
- [Server-Sent Events Specification][5]

[1]: https://fetch.spec.whatwg.org/#concept-request-body
[2]: https://fetch.spec.whatwg.org/#concept-response-body
[3]: https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API/Using_Fetch
[4]: https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream
[5]: https://html.spec.whatwg.org/multipage/server-sent-events.html
